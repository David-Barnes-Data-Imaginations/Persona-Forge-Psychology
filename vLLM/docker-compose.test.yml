# vllm/docker-compose.yml for single use outside framework
services:
  vllm:
    image: vllm/vllm-openai:gptoss
    container_name: vllm
    restart: unless-stopped
    ports:
      - "8006:8000"      # HTTP (OpenAI-compatible)
      - "8007:8001"      # Prometheus metrics (optional)
    environment:
      - MODEL_ID=openai/gpt-oss-20b
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - HF_TOKEN=${HF_TOKEN:-}
      - VLLM_WORKER_CONCURRENCY=1
      - VLLM_LOGGING_LEVEL=INFO
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    # Option A: use the Hugging Face model ID (recommended; will download into /models)
    command: >
      --model openai/gpt-oss-20b
      --dtype auto
      --download-dir /models
      --max-model-len 8192
      --api-key dummy
    # Option B: use a local model path (ensure config.json is at the path's top level)
    # command: >
    #   --model /models/gpt-oss-20b
    #   --dtype auto
    #   --download-dir /models
    #   --max-model-len 8192
    #   --api-key dummy
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia
    networks: [llmnet]

networks:
  llmnet: {}

